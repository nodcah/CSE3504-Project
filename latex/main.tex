%++++++++++++++++++++++++++++++++++++++++
% Don't modify this section unless you know what you're doing!
\documentclass[letterpaper,12pt]{article}
\usepackage{verbatim}
\usepackage{authblk}  % makes authors section look nice
\usepackage{tabularx} % extra features for tabular environment
\usepackage{amsmath}  % improve math presentation
\usepackage{graphicx} % takes care of graphic including machinery
\usepackage[margin=1in,letterpaper]{geometry} % decreases margins
\usepackage{cite} % takes care of citations
%++++++++++++++++++++++++++++++++++++++++


\begin{document}

\title{CSE 3504  Project 1}
\author[1]{Jack Davis}
\author[1]{Noah Del Coro}
\affil[1]{University of Connecticut, Electrical and Computer Engineering, Computer Science and Engineering}
\date{November 27th, 2018}
\maketitle

\section{Introduction}
Quite often, it is desirable to improve the performance of a given software by parallelizing tasks through use of threads.
While this modification alone can drastically improve software performance, it is still possible to further improve execution time efficiency.
It is very likely that threads will require access to shared data.
In order to prevent access collisions between threads, shared data is typically locked through a mutex.
Throughout this paper, we will refer to the code that accesses shared data as a Locked Access Shared Unit (LASU).
Because only one thread may access a LASU at a time, threads requesting access must sleep and wait for their turn.
Through use of clever scheduling, one may improve the performance of their software further by minimizing the amount of time threads spend waiting to access a LASU.
By taking into account the execution time of the Pre-lock Job (PLJ), the LASU, and the Remaining Job (RJ), one finds that the majority of cases are simple to resolve.
Two crucial algorithms for determining an efficient schedule include the First-Come First-Served (FCFS) algorithm, and the Longest-Remaining Job First (LRJF) algorithm.
These algorithms schedule threads by shortest PLJ first and longest RJ first, respectively.
In this paper, the authors discuss their implementation of these two algorithms and their findings on optimal solutions for various cases of PLJ, LASU, and RJ equality and inequality between threads.


\section{Methods}
The LRJF and FCFS algorithms were both implemented by sorting the matrix (list of threads) by either the first row or third row. 
For LRJF, we sorted the third row (remaining job time) largest to smallest.
For the FCFS, we sorted the first row (pre-lock job time) from smallest to largest.
The sorting algorithm we used is merge sort, which is implemented recursively. 
The psuedocode for FCFS and LRJF is seen below.
\begin{verbatim}
function FCFS(Matrix c):
    return mergesort_row(c, row=0, increasing)
    
function LRJF(Matrix c):
    return mergesort_row(c, row=2, decreasing)
\end{verbatim}


\section{Results}
To test the code, matrices of random numbers were generated based on the input conditions.
The inputs to this implementation were the number of threads to be simulated and the equality conditions.
The code then runs both algorithms (FCFS and LRJF) on the randomized matrix and outputs the total time each scheduling method would take to complete all threads. 
We also calculate the time that each individual thread finishes (the fourth row in the output matrices). 

Our main code that handles the input arguments is found in \texttt{scheduler.c}.
Here, we will also find the FCFS and LRJF functions that are found in pseudocode above.
However, the implementation of the \texttt{src/mergesort\_row} function, or any other matrix functions, are found in \texttt{src/utils/matrix.c}.
An example usage of our implementation is seen below. 
The first matrix displayed is the input matrix, then the next two are the FCFS and LRJF schedules, respectively.

\begin{verbatim}
$ ./scheduler 5 = . .
Running tests for 5 threads and configuration = . .
58	58	58	58	58	
52	38	43	95	14	
27	8	34	43	36	
==========================================
58	58	58	58	58	
14	95	43	38	52	
36	43	34	8	27	
108	210	244	256	327	

58	58	58	58	58	
95	14	43	52	38	
43	36	34	27	8	
196	203	244	289	308
==========================================
FCFS Total Time: 327
LRJF Total Time: 308
\end{verbatim}

\begin{table}[ht]
\begin{center}
\caption{Actual time the scheduling algorithm took given a matrix of threads of difference sizes. The two numbers correspond to FCFS and LRJF, respectively.}
\begin{tabular}{|c|ccc|} 
\hline
\multicolumn{1}{|c|}{$(PLJ, LASU, RJ)$} &
\multicolumn{1}{c}{5 Threads (ms)} &
\multicolumn{1}{c}{50 Threads (ms)} &
\multicolumn{1}{c|}{100 Threads (ms)} \\
\hline
= = = & 14, 7 & 52, 42 & 142, 120 \\
= = . & 22, 11 & 72, 62 & 132, 121 \\
= . = & 15, 8 & 73, 59 & 133, 115 \\
= . . & 17, 6 & 74, 62 & 133, 120 \\
. = = & 17, 6 & 75, 60 & 138, 115 \\
. . = & 12, 5 & 75, 58 & 136, 116 \\
\hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[ht]
\begin{center}
\caption{Run times given random thread lengths under certain conditions. All run times are in arbitrary time units. Tests run with only 5 threads.}
\begin{tabular}{|c|cc|} 
\hline
\multicolumn{1}{|c|}{$(PLJ, LASU, RJ)$} &
\multicolumn{1}{c}{$FCFS$} &
\multicolumn{1}{c|}{$LRJF$} \\
\hline
= = = & 313 & 313 \\
= = .  & 355 & 278 \\
= . = & 316 & 316 \\
= . . & 358 & 281 \\
. = = & 340 & 395 \\
. . = & 327 & 398 \\
\hline
\end{tabular}
\end{center}
\end{table}

$TODO$ Talk about finding an optimal solution here.  


\section{Conclusions}
From the results gathered from the simulations, a few patterns become apparent.
Firstly, the amount of time spent in the LASU does not have an affect on the most efficient scheduling of the threads.
The only affect that the LASU execution time has is on the overall execution time of the program.
The scheduling algorithm then only relies on the state of the PLJ and RJ execution times.
Namely, whether or not the PLJ execution time is equal across all threads dictates whether or not FCFS should be used, and whether or not the RJ execution time is equal across al threads dictates whether or not LRJF should be used.
If the PLJ execution time varies between threads, then the FCFS scheduling algorithm should be utilized, as it is more efficient to have a thread with a short PLJ to immediately begin working through its LASU instead of waiting.
This is because it will be able to process its LASU while the other threads are still working on their PLJ, minimizing time spent idle by the software.
Conversely, if the RJ execution time varies between threads, then the LRJF scheduling algorithm should be utilized, as it is more efficient to have a thread with a long RJ to begin working as soon as possible, such that the program will not hang on a single thread.
If the longest remaining job is executed first, it can be pushed to the front of the queue so that other threads may execute their LASU while the longest RJ is processing, minimizing idle time.

If both the PLJ and RJ portions are equal across all threads, the scheduling algorithm used does not matter, as each schedule will produce an equivalent execution time.
If the PLJ and RJ portions are both unequal across any threads, then more complex algorithms must be utilized to determine the optimal schedule.
Ultimately, this means that the use of either the FCFS or LRJF scheduling algorithm depends on if \textit{either} the PLJ or the RJ is unequal across threads.

In simpler cases, where it is unlikely that both the PLJ and RJ are unequal across threads, the execution time of these scheduling algorithms is rather fast.
Although this is a special case, it is very likely to occur in software, especially in circumstances in which threads act as workers upon the same task.
In these circumstances, threads will have either a similar PLJ or a similar RJ which allows for the use of these scheduling algorithms.

%++++++++++++++++++++++++++++++++++++++++
% References section will be created automatically 
% with inclusion of "thebibliography" environment
% as it shown below. See text starting with line
% \begin{thebibliography}{99}
% Note: with this approach it is YOUR responsibility to put them in order
% of appearance.

\begin{thebibliography}{99}

\bibitem{paper}
Ammar, Reda \& A. Fergany, Tahany \& I. El-Desouky, Ali \& Hefeeda, Mohamed. (1996). Heuristic scheduling algorithms to access the critical section in Shared Memory Environment. 

\end{thebibliography}


\end{document}

